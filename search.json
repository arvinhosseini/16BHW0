[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Country Temps Visualization/index.html",
    "href": "posts/Country Temps Visualization/index.html",
    "title": "Data Visualization and Databases",
    "section": "",
    "text": "Hello! Welcome to this blog post where I will go over how to use databases for data visualization. For this post we will be using example data of temperature data from various different countries.\n\n\nFirst we need to run the following line of code:\n\nimport plotly.graph_objects as go\nimport plotly.io as pio\n\npio.renderers.default = 'iframe'\n\n\nFor this post, we are going to be using SQL queries in order to retrevie our data. Then we are going to use some data visualization software to answer a few questions. We will be using sqlite to establish a database and to retreive our data.\n\n\n\nIn a seperate file, I already loaded in the data into a database named “database.db”. Thus we will connect to this database in order to get information about our data. The data we are using consists of three different tables: stations, countries, and temperatures. This data has been collected and shows the temperature readings of different stations in various countries over the years.\nWe will use this data to answer our first question: How does the average yearly change in temperature vary within a given country?\nThus we need to use an SQL query to acess the data that is useful for answering this question.\nWe will also need to include the headers necessary for the rest of the post.\n\nimport pandas as pd\nimport numpy as np\nimport sqlite3\nfrom sklearn.linear_model import LinearRegression\nimport plotly.express as px\n\nHere is the query we will use. The function allows a user a to input a database file, country, year_begin, year_end, and month to find the data needed to answer our question.\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    with sqlite3.connect(db_file) as conn:\n        cmd = f\"\"\"\n            SELECT\n                stations.NAME,\n                stations.LATITUDE,\n                stations.LONGITUDE,\n                countries.Name AS Country,\n                temperatures.Year,\n                temperatures.Month,\n                temperatures.Temp\n            FROM\n                temperatures\n            JOIN\n                stations ON temperatures.ID = stations.ID\n            JOIN\n                countries ON SUBSTR(stations.ID, 1, 2) = SUBSTR(countries.\"FIPS 10-4\", 1, 2)\n            WHERE\n                countries.Name = '{country}'\n                AND temperatures.Year BETWEEN {year_begin} AND {year_end}\n                AND temperatures.Month = {month}\n        \"\"\"\n\n        # Execute the query and read the results into a DataFrame\n        result_df = pd.read_sql_query(cmd, conn)\n    conn.close()\n    return result_df\n\nNow in our dataframe we have the data that we will use the answer our question: the station’s name, latitude, and longitude, the country’s name, and the tempature of the country and the month we are looking at. This data is stored in result_df.\nThus, we can now write a fucntion, temperature_coefficient_plot to use the pulled data and make a plot. The goal of this function is to create a plot of the selected country with a scatter of data points located at the stations used. Each datapoint will store information about the average yearly change in temperature for the associated station.\nThe function uses the same variables as the previous function, in addition to mins_obs, zoom, mapbox_style, and color_continuous_scale. mins_obs is an inputed variable that only shows stations that have at least mins_obs years of observatoin. The other variables, zoom, mapbox_style, and color_continuous_scale, are for graphing preference of the plot.\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, zoom =2, mapbox_style=\"carto-positron\", color_continuous_scale=px.colors.diverging.RdGy_r ):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n\n    grouped_df = df.groupby(\"NAME\")\n\n    dfs_dict = {name: group for name, group in grouped_df}\n\n    filtered_dfs_dict = {name: group_df for name, group_df in dfs_dict.items() if len(group_df) &gt;= min_obs}\n\n    def coef(data_group):\n        x = data_group[[\"Year\"]]\n        y = data_group[\"Temp\"]\n        LR = LinearRegression()\n        LR.fit(x, y)\n        return LR.coef_[0]\n\n    results = pd.DataFrame()\n    for name, filtered_df in filtered_dfs_dict.items():\n        temp_change = filtered_df.groupby(\"NAME\").apply(coef).reset_index(name='temp_change')\n    \n        latitude = filtered_df[\"LATITUDE\"].iloc[0]\n        longitude = filtered_df[\"LONGITUDE\"].iloc[0]\n\n        result_row = pd.DataFrame({\n            \"NAME\": [name],\n            \"LATITUDE\": [latitude],\n            \"LONGITUDE\": [longitude],\n            \"EXPECTED_CHANGE\": [temp_change[\"temp_change\"].iloc[0]]\n        })\n\n        results = results._append(result_row, ignore_index=True)\n\n    fig = px.scatter_mapbox(\n    results,\n    lat=\"LATITUDE\",\n    lon=\"LONGITUDE\",\n    text=\"NAME\",\n    color=\"EXPECTED_CHANGE\",\n    color_continuous_scale=color_continuous_scale,\n    size_max=30,\n    zoom=zoom,\n    mapbox_style=mapbox_style,\n    title=f\"Expected Temperature Change in {country} ({year_begin}-{year_end}), Month {month}\",\n    )\n\n    fig.show()\n\nThe function first pulls the df using the query_climate_database function, then groups the results by station name.\nThis is what the data frame would look like after being grouped.\n\n#Example data\n(db_file, country, year_begin, year_end, month, min_obs) = (\"database.db\", \"India\", 1980, 2020, 1, 10)\n\ndf = query_climate_database(db_file, country, year_begin, year_end, month)\n\ngrouped_df = df.groupby(\"NAME\")\n\ngrouped_df.head()\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n23.48\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n24.57\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n24.19\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n23.51\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n24.81\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3145\nDARJEELING\n27.050\n88.270\nIndia\n1981\n1\n6.50\n\n\n3146\nDARJEELING\n27.050\n88.270\nIndia\n1982\n1\n8.70\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n5.10\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n6.90\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n8.10\n\n\n\n\n516 rows × 7 columns\n\n\n\nNext, the function creates a seperate dataframe for each station that contains all that stations data. It also filters out any statoins with less than mins_obs years of data. It will store these dataframes in a dictionary where the key will be the name of the station.\nNow that we have the dictionary of station’s data, we use linear regression from the scikit.learn libray, to fit a line of best fit for each station. Thus, the slope of this line will be the rate of change for the temperature at the given station. We will put each station and its rate of change in a seperate dataframe along with the station longitude and latitude. This information will be stored in a dataframe called results.\nSo the list of the rates of change will look like the following.\n\n# create dictionary for dataframes, each keyed by the unique \"NAME\"\ndfs_dict = {name: group for name, group in grouped_df}\n\nfiltered_dfs_dict = {name: group_df for name, group_df in dfs_dict.items() if len(group_df) &gt;= min_obs}\n\n#calculate expected change in temp for each station\ndef coef(data_group):\n    x = data_group[[\"Year\"]]\n    y = data_group[\"Temp\"]\n    LR = LinearRegression()\n    LR.fit(x, y)\n    return LR.coef_[0]\n\nresults = pd.DataFrame()\n\nfor name, filtered_df in filtered_dfs_dict.items():\n        temp_change = filtered_df.groupby(\"NAME\").apply(coef).reset_index(name='temp_change')\n    \n        latitude = filtered_df[\"LATITUDE\"].iloc[0]\n        longitude = filtered_df[\"LONGITUDE\"].iloc[0]\n\n        result_row = pd.DataFrame({\n            \"NAME\": [name],\n            \"LATITUDE\": [latitude],\n            \"LONGITUDE\": [longitude],\n            \"EXPECTED_CHANGE\": [temp_change[\"temp_change\"].iloc[0]]\n        })\n\n        results = results._append(result_row, ignore_index=True)\n\nresults\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nEXPECTED_CHANGE\n\n\n\n\n0\nAGARTALA\n23.883\n91.250\n-0.006184\n\n\n1\nAHMADABAD\n23.067\n72.633\n0.006731\n\n\n2\nAKOLA\n20.700\n77.033\n-0.008063\n\n\n3\nALLAHABAD\n25.441\n81.735\n-0.029375\n\n\n4\nALLAHABAD_BAMHRAULI\n25.500\n81.900\n-0.015457\n\n\n...\n...\n...\n...\n...\n\n\n92\nTRIVANDRUM\n8.500\n77.000\n0.022892\n\n\n93\nUDAIPUR_DABOK\n24.617\n73.883\n0.072424\n\n\n94\nVARANASI_BABATPUR\n25.450\n82.867\n-0.012996\n\n\n95\nVERAVAL\n20.900\n70.367\n0.024848\n\n\n96\nVISHAKHAPATNAM\n17.717\n83.233\n-0.034050\n\n\n\n\n97 rows × 4 columns\n\n\n\nFinally, using plotly, we will graph this data on the plot of the chosen country. The function temperature_coefficient_plot has the variables, zoom, mapbox_style, and color_continuous_scale, predefined. Thus a user can choose to input their own prefrences for these variables but if not it will be set to the setting chosen in the function declaration.\nLet’s use our new function to look a plot of an example country. For example lets look at the country of India from years 1980-2020, during the month of January. For this example, we will use a min_obs of 10 years and use the default settings for the plotly graph.\n\n# Example variables\n(country, year_begin, year_end, month, min_obs) = (\"India\", 1980, 2020, 1, 10)\n\n# Call function\ntemperature_coefficient_plot(\"database.db\", country, year_begin, year_end, month, min_obs)\n\n\n\n\nAs we can see an interactive graph was produced by our function. We can zoom in and out on the graph and we are also able to hover over the datapoints to see what the expected rate of change of temperature will be. We can also see that there is a scale on the right that shows how the color of the data point correlates to the rate of change."
  },
  {
    "objectID": "posts/Country Temps Visualization/index.html#set-up",
    "href": "posts/Country Temps Visualization/index.html#set-up",
    "title": "Data Visualization and Databases",
    "section": "",
    "text": "First we need to run the following line of code:\n\nimport plotly.graph_objects as go\nimport plotly.io as pio\n\npio.renderers.default = 'iframe'\n\n\nFor this post, we are going to be using SQL queries in order to retrevie our data. Then we are going to use some data visualization software to answer a few questions. We will be using sqlite to establish a database and to retreive our data."
  },
  {
    "objectID": "posts/Country Temps Visualization/index.html#first-question-and-query",
    "href": "posts/Country Temps Visualization/index.html#first-question-and-query",
    "title": "Data Visualization and Databases",
    "section": "",
    "text": "In a seperate file, I already loaded in the data into a database named “database.db”. Thus we will connect to this database in order to get information about our data. The data we are using consists of three different tables: stations, countries, and temperatures. This data has been collected and shows the temperature readings of different stations in various countries over the years.\nWe will use this data to answer our first question: How does the average yearly change in temperature vary within a given country?\nThus we need to use an SQL query to acess the data that is useful for answering this question.\nWe will also need to include the headers necessary for the rest of the post.\n\nimport pandas as pd\nimport numpy as np\nimport sqlite3\nfrom sklearn.linear_model import LinearRegression\nimport plotly.express as px\n\nHere is the query we will use. The function allows a user a to input a database file, country, year_begin, year_end, and month to find the data needed to answer our question.\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    with sqlite3.connect(db_file) as conn:\n        cmd = f\"\"\"\n            SELECT\n                stations.NAME,\n                stations.LATITUDE,\n                stations.LONGITUDE,\n                countries.Name AS Country,\n                temperatures.Year,\n                temperatures.Month,\n                temperatures.Temp\n            FROM\n                temperatures\n            JOIN\n                stations ON temperatures.ID = stations.ID\n            JOIN\n                countries ON SUBSTR(stations.ID, 1, 2) = SUBSTR(countries.\"FIPS 10-4\", 1, 2)\n            WHERE\n                countries.Name = '{country}'\n                AND temperatures.Year BETWEEN {year_begin} AND {year_end}\n                AND temperatures.Month = {month}\n        \"\"\"\n\n        # Execute the query and read the results into a DataFrame\n        result_df = pd.read_sql_query(cmd, conn)\n    conn.close()\n    return result_df\n\nNow in our dataframe we have the data that we will use the answer our question: the station’s name, latitude, and longitude, the country’s name, and the tempature of the country and the month we are looking at. This data is stored in result_df.\nThus, we can now write a fucntion, temperature_coefficient_plot to use the pulled data and make a plot. The goal of this function is to create a plot of the selected country with a scatter of data points located at the stations used. Each datapoint will store information about the average yearly change in temperature for the associated station.\nThe function uses the same variables as the previous function, in addition to mins_obs, zoom, mapbox_style, and color_continuous_scale. mins_obs is an inputed variable that only shows stations that have at least mins_obs years of observatoin. The other variables, zoom, mapbox_style, and color_continuous_scale, are for graphing preference of the plot.\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, zoom =2, mapbox_style=\"carto-positron\", color_continuous_scale=px.colors.diverging.RdGy_r ):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n\n    grouped_df = df.groupby(\"NAME\")\n\n    dfs_dict = {name: group for name, group in grouped_df}\n\n    filtered_dfs_dict = {name: group_df for name, group_df in dfs_dict.items() if len(group_df) &gt;= min_obs}\n\n    def coef(data_group):\n        x = data_group[[\"Year\"]]\n        y = data_group[\"Temp\"]\n        LR = LinearRegression()\n        LR.fit(x, y)\n        return LR.coef_[0]\n\n    results = pd.DataFrame()\n    for name, filtered_df in filtered_dfs_dict.items():\n        temp_change = filtered_df.groupby(\"NAME\").apply(coef).reset_index(name='temp_change')\n    \n        latitude = filtered_df[\"LATITUDE\"].iloc[0]\n        longitude = filtered_df[\"LONGITUDE\"].iloc[0]\n\n        result_row = pd.DataFrame({\n            \"NAME\": [name],\n            \"LATITUDE\": [latitude],\n            \"LONGITUDE\": [longitude],\n            \"EXPECTED_CHANGE\": [temp_change[\"temp_change\"].iloc[0]]\n        })\n\n        results = results._append(result_row, ignore_index=True)\n\n    fig = px.scatter_mapbox(\n    results,\n    lat=\"LATITUDE\",\n    lon=\"LONGITUDE\",\n    text=\"NAME\",\n    color=\"EXPECTED_CHANGE\",\n    color_continuous_scale=color_continuous_scale,\n    size_max=30,\n    zoom=zoom,\n    mapbox_style=mapbox_style,\n    title=f\"Expected Temperature Change in {country} ({year_begin}-{year_end}), Month {month}\",\n    )\n\n    fig.show()\n\nThe function first pulls the df using the query_climate_database function, then groups the results by station name.\nThis is what the data frame would look like after being grouped.\n\n#Example data\n(db_file, country, year_begin, year_end, month, min_obs) = (\"database.db\", \"India\", 1980, 2020, 1, 10)\n\ndf = query_climate_database(db_file, country, year_begin, year_end, month)\n\ngrouped_df = df.groupby(\"NAME\")\n\ngrouped_df.head()\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n23.48\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n24.57\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n24.19\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n23.51\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n24.81\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3145\nDARJEELING\n27.050\n88.270\nIndia\n1981\n1\n6.50\n\n\n3146\nDARJEELING\n27.050\n88.270\nIndia\n1982\n1\n8.70\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n5.10\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n6.90\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n8.10\n\n\n\n\n516 rows × 7 columns\n\n\n\nNext, the function creates a seperate dataframe for each station that contains all that stations data. It also filters out any statoins with less than mins_obs years of data. It will store these dataframes in a dictionary where the key will be the name of the station.\nNow that we have the dictionary of station’s data, we use linear regression from the scikit.learn libray, to fit a line of best fit for each station. Thus, the slope of this line will be the rate of change for the temperature at the given station. We will put each station and its rate of change in a seperate dataframe along with the station longitude and latitude. This information will be stored in a dataframe called results.\nSo the list of the rates of change will look like the following.\n\n# create dictionary for dataframes, each keyed by the unique \"NAME\"\ndfs_dict = {name: group for name, group in grouped_df}\n\nfiltered_dfs_dict = {name: group_df for name, group_df in dfs_dict.items() if len(group_df) &gt;= min_obs}\n\n#calculate expected change in temp for each station\ndef coef(data_group):\n    x = data_group[[\"Year\"]]\n    y = data_group[\"Temp\"]\n    LR = LinearRegression()\n    LR.fit(x, y)\n    return LR.coef_[0]\n\nresults = pd.DataFrame()\n\nfor name, filtered_df in filtered_dfs_dict.items():\n        temp_change = filtered_df.groupby(\"NAME\").apply(coef).reset_index(name='temp_change')\n    \n        latitude = filtered_df[\"LATITUDE\"].iloc[0]\n        longitude = filtered_df[\"LONGITUDE\"].iloc[0]\n\n        result_row = pd.DataFrame({\n            \"NAME\": [name],\n            \"LATITUDE\": [latitude],\n            \"LONGITUDE\": [longitude],\n            \"EXPECTED_CHANGE\": [temp_change[\"temp_change\"].iloc[0]]\n        })\n\n        results = results._append(result_row, ignore_index=True)\n\nresults\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nEXPECTED_CHANGE\n\n\n\n\n0\nAGARTALA\n23.883\n91.250\n-0.006184\n\n\n1\nAHMADABAD\n23.067\n72.633\n0.006731\n\n\n2\nAKOLA\n20.700\n77.033\n-0.008063\n\n\n3\nALLAHABAD\n25.441\n81.735\n-0.029375\n\n\n4\nALLAHABAD_BAMHRAULI\n25.500\n81.900\n-0.015457\n\n\n...\n...\n...\n...\n...\n\n\n92\nTRIVANDRUM\n8.500\n77.000\n0.022892\n\n\n93\nUDAIPUR_DABOK\n24.617\n73.883\n0.072424\n\n\n94\nVARANASI_BABATPUR\n25.450\n82.867\n-0.012996\n\n\n95\nVERAVAL\n20.900\n70.367\n0.024848\n\n\n96\nVISHAKHAPATNAM\n17.717\n83.233\n-0.034050\n\n\n\n\n97 rows × 4 columns\n\n\n\nFinally, using plotly, we will graph this data on the plot of the chosen country. The function temperature_coefficient_plot has the variables, zoom, mapbox_style, and color_continuous_scale, predefined. Thus a user can choose to input their own prefrences for these variables but if not it will be set to the setting chosen in the function declaration.\nLet’s use our new function to look a plot of an example country. For example lets look at the country of India from years 1980-2020, during the month of January. For this example, we will use a min_obs of 10 years and use the default settings for the plotly graph.\n\n# Example variables\n(country, year_begin, year_end, month, min_obs) = (\"India\", 1980, 2020, 1, 10)\n\n# Call function\ntemperature_coefficient_plot(\"database.db\", country, year_begin, year_end, month, min_obs)\n\n\n\n\nAs we can see an interactive graph was produced by our function. We can zoom in and out on the graph and we are also able to hover over the datapoints to see what the expected rate of change of temperature will be. We can also see that there is a scale on the right that shows how the color of the data point correlates to the rate of change."
  },
  {
    "objectID": "posts/Country Temps Visualization/index.html#question-3-how-does-the-temperature-vary-across-different-latitudes-within-a-specific-country-for-a-given-month",
    "href": "posts/Country Temps Visualization/index.html#question-3-how-does-the-temperature-vary-across-different-latitudes-within-a-specific-country-for-a-given-month",
    "title": "Data Visualization and Databases",
    "section": "Question 3: How does the temperature vary across different latitudes within a specific country for a given month?",
    "text": "Question 3: How does the temperature vary across different latitudes within a specific country for a given month?\nThis next question we try to answer is intruiging as we can see if there is a correlation between latitude and temperature for a country within a given month.\nWe first must define our new query function, query_temperature_by_latitude, which requires a user to input a county and a month to be visualized.\nThe query returns the name and latitude of the station as well as the average temperature for the selected station.\n\ndef query_temperature_by_latitude(db_file, country, month):\n    with sqlite3.connect(db_file) as conn:\n        cmd = f\"\"\"\n            SELECT\n                stations.NAME,\n                stations.LATITUDE,\n                AVG(temperatures.Temp) AS AvgTemperature\n            FROM\n                temperatures\n            JOIN\n                stations ON temperatures.ID = stations.ID\n            JOIN\n                countries ON SUBSTR(stations.ID, 1, 2) = SUBSTR(countries.\"FIPS 10-4\", 1, 2)\n            WHERE\n                countries.Name = '{country}'\n                AND temperatures.Month = {month}\n            GROUP BY\n                stations.NAME, stations.LATITUDE\n            ORDER BY\n                stations.LATITUDE\n        \"\"\"\n\n        result_df = pd.read_sql_query(cmd, conn)\n\n    return result_df\n\nLet’s take a look at what this resulting data frame will look like, using the United States and the month of March.\n\ndf = query_temperature_by_latitude(db_file, \"United States\", 3)\ndf\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nAvgTemperature\n\n\n\n\n0\nNAALEHU_14\n19.0614\n21.607500\n\n\n1\nKIOLAKAA_7\n19.0667\n20.521212\n\n\n2\nSOUTH_KONA_2232\n19.0825\n18.292609\n\n\n3\nSEA_MTN_1215\n19.1336\n22.496250\n\n\n4\nPAHALA_21\n19.1986\n19.954773\n\n\n...\n...\n...\n...\n\n\n12548\nALPINE\n70.3464\n-22.067143\n\n\n12549\nCOLVILLE_VILLAGE\n70.4322\n-25.835909\n\n\n12550\nWAINWRIGHT_AP\n70.6392\n-24.802381\n\n\n12551\nBARROW_POST_ROGERS_AP\n71.2833\n-25.335980\n\n\n12552\nBARROW_4_ENE\n71.3214\n-23.970000\n\n\n\n\n12553 rows × 3 columns\n\n\n\nNext, we define our function plot_temperature_by_latitude, that will give us the scatter plot of all the stations used.\nThe function again uses the plotly library to produce the graph.\n\ndef plot_temperature_by_latitude(db_file, country, month):\n    result_df = query_temperature_by_latitude(db_file, country, month)\n\n    if result_df.empty:\n        print(\"No data available for the specified parameters.\")\n        return\n\n    fig = px.scatter(\n        result_df,\n        x=\"LATITUDE\",\n        y=\"AvgTemperature\",\n        color=\"AvgTemperature\",\n        size_max=20, \n        title=f\"Temperature Variation by Latitude in {country}, Month {month}\",\n        labels={\"LATITUDE\": \"Latitude\", \"AvgTemperature\": \"Average Temperature\"},\n        hover_name=\"NAME\",\n    )\n\n    fig.show()\n\nNow that we have defined our plotting function, let’s plot the temperatures in the United States and see if we can find any interesting trends.\n\nplot_temperature_by_latitude(db_file, \"United States\", 3)\n\n\n\n\nAs we can see in the plot, there is a clear trend in the United States. As latitude inrcreaes, the average temperature decreases. This intuitively makes sense as we see that the stations in Hawaii are the warmest, while the stations in Alaska are the coldest. This placement is correct as we know that Hawaii is one of the hotest states and Alaska one of the coldest.\nThe graph is also interactive as the user is able to hover over each scatterpoint on the graph and check its latitude and average temperature. There is also a color coded scale on the right that shows the warmer stations as warm colors (yellow, orange) and the colder staions as cold colors (purple, blue)."
  },
  {
    "objectID": "posts/Country Temps Visualization/index.html#conclusion",
    "href": "posts/Country Temps Visualization/index.html#conclusion",
    "title": "Data Visualization and Databases",
    "section": "Conclusion",
    "text": "Conclusion\nIn conlusion, we can see how helpful SQL and graphing software like plotly can be for data visualization. I hope that you enjoyed reading my blog post and learned something interesting!"
  },
  {
    "objectID": "posts/Tutorial/index.html",
    "href": "posts/Tutorial/index.html",
    "title": "Data Visualization Tutorial",
    "section": "",
    "text": "Hello! Welcome to my Data Visualization Tutorial. For the tutorial, I will be using the Palmer Penguins data set. The url for this data set can be found below.\nThe first step is to import pandas and load in the data set.\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)"
  },
  {
    "objectID": "posts/Tutorial/index.html#intro-and-set-up",
    "href": "posts/Tutorial/index.html#intro-and-set-up",
    "title": "Data Visualization Tutorial",
    "section": "",
    "text": "Hello! Welcome to my Data Visualization Tutorial. For the tutorial, I will be using the Palmer Penguins data set. The url for this data set can be found below.\nThe first step is to import pandas and load in the data set.\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)"
  },
  {
    "objectID": "posts/Tutorial/index.html#using-head-and-info-functions",
    "href": "posts/Tutorial/index.html#using-head-and-info-functions",
    "title": "Data Visualization Tutorial",
    "section": "Using Head() and Info() Functions",
    "text": "Using Head() and Info() Functions\nNext, we can look at what the data looks like using the head and describe function in pandas.\n\npenguins.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/07\n39.1\n18.7\n181.0\n3750.0\nMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/07\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n11/16/07\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n3\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n11/16/07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAdult not sampled.\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n11/16/07\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n\n\n\n\n\n\npenguins.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 17 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   studyName            344 non-null    object \n 1   Sample Number        344 non-null    int64  \n 2   Species              344 non-null    object \n 3   Region               344 non-null    object \n 4   Island               344 non-null    object \n 5   Stage                344 non-null    object \n 6   Individual ID        344 non-null    object \n 7   Clutch Completion    344 non-null    object \n 8   Date Egg             344 non-null    object \n 9   Culmen Length (mm)   342 non-null    float64\n 10  Culmen Depth (mm)    342 non-null    float64\n 11  Flipper Length (mm)  342 non-null    float64\n 12  Body Mass (g)        342 non-null    float64\n 13  Sex                  334 non-null    object \n 14  Delta 15 N (o/oo)    330 non-null    float64\n 15  Delta 13 C (o/oo)    331 non-null    float64\n 16  Comments             26 non-null     object \ndtypes: float64(6), int64(1), object(10)\nmemory usage: 45.8+ KB\n\n\nAs we can see from the displayed info, there are 344 entries in the dataframe as well as 17 different columns that are associated with each entry. So each data point has a studyName, Sample Number, ect. We can see that some columns, such as Comments or Body Mass, have a non-Null count of under 344. This means that some data entries in the dataframe do not have any values for some of these columns.\nFor this tuturial, lets look at the following four columns :‘culmen length’, ‘culmen depth’, ‘flipper length’, ‘body mass’ and see how they compare based on the study. Since some of these are null, lets remove the rows that have a null value for at least one of these columns.\n\ncolumns_of_interest = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\ndf_cleaned = penguins.dropna(subset=columns_of_interest)\n\n\ndf_cleaned.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 342 entries, 0 to 343\nData columns (total 17 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   studyName            342 non-null    object \n 1   Sample Number        342 non-null    int64  \n 2   Species              342 non-null    object \n 3   Region               342 non-null    object \n 4   Island               342 non-null    object \n 5   Stage                342 non-null    object \n 6   Individual ID        342 non-null    object \n 7   Clutch Completion    342 non-null    object \n 8   Date Egg             342 non-null    object \n 9   Culmen Length (mm)   342 non-null    float64\n 10  Culmen Depth (mm)    342 non-null    float64\n 11  Flipper Length (mm)  342 non-null    float64\n 12  Body Mass (g)        342 non-null    float64\n 13  Sex                  334 non-null    object \n 14  Delta 15 N (o/oo)    330 non-null    float64\n 15  Delta 13 C (o/oo)    331 non-null    float64\n 16  Comments             25 non-null     object \ndtypes: float64(6), int64(1), object(10)\nmemory usage: 48.1+ KB\n\n\nWe can see that two rows got dropped from the dataframe, as the total number of entries is now 342."
  },
  {
    "objectID": "posts/Tutorial/index.html#visualization-using-box-plot",
    "href": "posts/Tutorial/index.html#visualization-using-box-plot",
    "title": "Data Visualization Tutorial",
    "section": "Visualization using Box Plot",
    "text": "Visualization using Box Plot\nNext, we can use matplotlib to visualize some of the data, using these four columns that we are intersted in.\n\n#import matplotlib\nimport matplotlib.pyplot as plt\n\nNow we can write a basic for loop that displays the box plot for each of these four columns.\n\nfor column in columns_of_interest:\n    plt.figure(figsize=(8, 5))\n    df_cleaned[column].plot(kind='box', vert=False)\n    plt.title(f'Box Plot for {column}')\n    plt.xlabel(column)\n    plt.show()"
  },
  {
    "objectID": "posts/Tutorial/index.html#visualization-with-seaborn-and-scatterplots",
    "href": "posts/Tutorial/index.html#visualization-with-seaborn-and-scatterplots",
    "title": "Data Visualization Tutorial",
    "section": "Visualization with Seaborn and Scatterplots",
    "text": "Visualization with Seaborn and Scatterplots\nWe can also use a software seaborn, a data visualization tool, help with our data.\n\nimport seaborn as sns\n\nWe can use seaborn to display scatter plots that compare each of the columns againist each other in order to find certain trends.\n\nsns.pairplot(df_cleaned[columns_of_interest])\nplt.suptitle('Scatter Plots for Culmen Length, Culmen Depth, Flipper Length, and Body Mass', y=1.02)\nplt.show()\n\n\n\n\nAs we can see there are a total of 16 plots shown, and when we have a case of the column vs itself, a bar graph is displayed which shows the amount of category. From these charts we can make some insights. For example we can see that there is a relationship between flipper length and body mass. From the scatter plot, we can see that as flipper length increases, so does the body mass."
  },
  {
    "objectID": "posts/Tutorial/index.html#conclusion",
    "href": "posts/Tutorial/index.html#conclusion",
    "title": "Data Visualization Tutorial",
    "section": "Conclusion",
    "text": "Conclusion\nThank you for reading this post!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Hello! Here is my welcome post for my new blog!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Arvin Hosseini’s Blog",
    "section": "",
    "text": "Data Visualization and Databases\n\n\n\n\n\n\n\nTutorials\n\n\n\n\n\n\n\n\n\n\n\nFeb 3, 2024\n\n\nArvin Hosseini\n\n\n\n\n\n\n  \n\n\n\n\nData Visualization Tutorial\n\n\n\n\n\n\n\ntutorials\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2024\n\n\nArvin Hosseini\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2024\n\n\nArvin Hosseini\n\n\n\n\n\n\nNo matching items"
  }
]